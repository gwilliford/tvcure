
\begin{document}
%\footnote{Monogan, Andy, Danny, Amanda, Josh, Doug, Annie, Discussants (PolMeth, SLAMM, Minnesota), Fred Boehmke, Clay Webb, Sara Mitchell}
% Previous versions of this paper were presented at POLMETH and SLAMM and ISA
% International Studies Association Annual Conferences, March 27-31, 2019.

\begin{center}
\textbf{Semiparametric Cure Models and the Duration of Peace After Interstate War}

George W. Williford

The University of Georgia

williford@uga.edu

\today

\vspace{8cm}



\end{center}

%\noindent\textbf{Abstract:} 
\pagebreak

Survival analysis has become one of the fundamental components of the political scientist's methodological toolkit. Over the past few decades these techniques have been widely applied to analyze a diverse array of phenomena including  congressional position taking \citep{box-steffensmeier1997}, the confirmation of executive nominees \citep{ostrander2015}, regime change \citep{gates2016}, cabinet duration \citep{somer-topcu2008}, the duration of peace-agreements \citep{fortna2004b}, and war duration \citep{weisiger2013}. One of the primary advantages of duration modeling techniques is their ability to deal with censored observations. By incorporating information on observations that have yet to fail into the estimation process, these models allow analysts to retain valuable information about the failure process and avoid the potential for bias introduced by the censoring process. 

Standard duration models make a key assumption that is often overlooked by many analysts. Survival models typically assume that all subjects eventually experience the event of interest: although some observations are not observed to fail and are thus considered censored, the model still assumes that they will fail at some point in the future. Although this assumption is sometimes justified (e.g., all humans eventually die), for many subjects of interest this assumption is untenable. Conflict recurrence is a prime example of one such subject; although many conflicts will recur in the future, many combatants are unlikely to fight again on any reasonable timescale. 

To the extent that some subjects are “immune” to failure, the assumption that all units eventually fail is violated. This has potential consequences for both the accuracy of the coefficient estimates and the inferences derived from duration models. Neglecting violations of this assumption by including observations that are not at risk of failure has the potential to produce biased estimates of covariate effects on the observations that are actually at risk. Moreover, if some observations are at risk of failure while others or not, it is often of interest to model which factors influence whether an observation is at risk.

% However, in doing so, standard duration models assume that all censored observations eventually experience the event of interest. Although this assumption is sometimes justified (e.g., all political leaders will eventually lose office and all wars will eventually terminate), in many cases it is not. For example, it is difficult to justify the argument that all peace agreements will eventually fail and result in renewed conflict between the former belligerents. 
% TODO Basic description of cure models
% Typically, cure models involve the use of mixture models to estimate the latent probability that an individual fails and then adjust the estimates of duration time accordingly. The use of these models 
% Bias
% Heterogenous Risk
% Theoretical

% Short description of cure models
To deal with these issues, scholars in biostatistics and related fields have developed models known as \textit{cure models}. Cure models are designed to deal with the fact that some subjects under observation may be ``cured'' of a particular disease and therefore immune to failure.\footnote{These individuals are also referred to as ``long-term survivors.''} Typically, cure models involve the use of mixture models to estimate the latent probability that an individual fails and then adjust the estimates of duration time accordingly. 

In addition to correcting for potential bias, the use of cure models allows analysts to gain additional theoretical leverage over questions of substantive interest. By jointly modeling whether a unit experiences an event of interest and when that unit fails, scholars can gain additional insight into how a variable influences an outcome of interest: by affecting the probability of eventual failure or by influencing the time until failure.
%To deal with these issues, scholars in biostatistics and related fields have developed \textit{cure models}. Cure models extend standard models for duration data to explicitly model the fact that some observations are not susceptible to the event of interest and are thus ``immune'' or ``cured.'' 
For example, \citep{svolik2008} uses cure models to examine authoritarian reversals among democratic regimes. This example nicely illustrates how cure models can be used to improve substantive inferences. In part, \citep{svolik2008} tests the effects of various economic variables on both whether a democracy is cured (``consolidated democracies'') or are still at risk of authoritarian reversals (``transitional democracies''). He finds that a country's level of economic development determines whether a democracy is susceptible to a reversal, where highly developed countries are substantially more likely to be consolidated democracies. By contrast, economic recessions do not affect whether a country is susceptible, but does influence the timing of authoritarian reversals among transitional democracies. 

% Each of these applications employs parametric cure models. Although these are appropriate under the right conditions, in many cases, the use of parametric estimators may not be appropriate. The use of parametric models is only appropriate when analysts are comfortable making assumptions about the distribution of the failure times and/or the shape of the baseline hazard. Incorrectly imposing a particular parametric form on the data represents a form of specification bias that has the potential to influence the results obtained from a model \citep{box2004a}. Thus, in the absence of strong theoretical expectations about the shape of the baseline hazard, the use of semi-parametric duration models is more appropriate.
To date, cure models have seen limited use in political science. In addition to \citep{svolik2008}, cure models have been applied in studies of congressional responses to supreme court rulings \citep{hettinger2005}, the consolidation of democratic regimes \citep{svolik2008}, third-party intervention in civil war \citep{findley2006}, the onset of interstate conflict \citep{clark2003}, and campaign contributions to members of Congress \citep{box2005}.

%\citet{hettinger2005} use cure models to examine decisions to Congressional override Supreme Court rulings. They find that the salience of individual cases influences whether Congress overrides the Court, while characteristics of the legal decision (???) affect the timing of such decisions. 
% in studies of congressional responses to supreme court rulings \citep{hettinger2005}, the consolidation of democratic regimes \citep{svolik2008}, third-party intervention in civil war \citep{findley2006}, the onset of interstate conflict \citep{clark2003}, and campaign contributions to members of Congress \citep{box2005}. However, each of these studies employs cure models that model the hazard rate parametrically. Although these are appropriate under the right conditions, the use of parametric estimators may not be appropriate for many phenomena of interest. Incorrectly imposing a particular parametric form on the data represents a form of specification bias that has the potential to influence the results obtained from a model \citep{box2004a}. Thus, in the absence of strong theoretical expectations about the shape of the baseline hazard, the use of semiparametric models provides a safer alternative. 

This article is designed to introduce readers to cure models, with a particular emphasis on semiparametric cure models. In doing so, it makes several contributions. First, it begins by discussing the potential problems associated with standard duration models and introducing readers to the semiparametric cure model. Second, I introduce a new R package, \textbf{tvcure}, which will be made publicly available upon publication. This software is designed to remedy shortcomings in existing software packages for implementing these models. Unlike existing software, the \textbf{tvcure} package is designed to estimate semiparametric cure models with time-varying covariates. 
%In addition, it allows users to implement the Firth correction (Firth 1993) as a means of dealing with perfect predictors, a common problem encountered when dealing with cure models. 
%Control for the influence a covariate has on the probability of failure, the 
%Control for when
%Parametric cure models

% Monte Carlo Simulations
%Third, I conduct Monte Carlo simulations to evaluate the extent to which cured observations produce bias in the estimated coefficients. By varying the proportion of cured observations in the data, I assess the extent to which these observations may influence the results of a model.
%To demonstrate the utility of the ZIP model, I conduct a series of Monte Carlo simulations to evaluate its performance relative to other models with various proportions of cured observations in all data. These simulations demonstrate that the ZIP model consistently outperforms the Cox model at returning unbiased estimates of the original coefficients. In addition, I compare the performance of the ZIP model to a mixture Weibull model. I find that the ZIP model performs comparably when the data contains relatively low proportions of cured observations. Moreover, I find that the ZIP model actually outperforms the Weibull model when the data contains higher proportions of cured subjects, even when the simulated failure times are drawn from a Weibull distribution. %In addition, I assess the performance of the ZIP estimator at various levels of cured or inflated observations in terms of convergence and separation. %TODO Reword this

% Application
I illustrate the utility of this model by conducting an analysis of international cease-fire agreements using data on international ceasefires from \citet{lo2008}.% \citet{fortna2004b, werner2005, lo2008}. 
%Produce sizable changes in the coefficient estimates of several independent variables that influence the inferences drawn from the model. Moreover, by jointly modeling the influence of these covariates on the probability of failure and the time until failure, I demonstrate how cure models can be used to parse between competing hypotheses regarding the effects of several variables on the prospects of successful cease-fire agreements.
%Finally, to illustrate the potential for cure models to be applied broadly within political science and other fields, I apply the model to data on the duration of peace after civil conflict.
This analysis illustrates how cure models can provide more nuanced understandings of the theoretical mechanisms that lead to peace after war by distinguishing between covariates that affect the probability of peace agreement failure and those that affect the duration of agreements. 
%For example, some scholars have argued that third party interventions in civil conflicts increase the duration of peace while they remain in the country but undermine the likelihood of a successful resolution in the long term. 
%Cure models can be used to examine this argument by testing whether third party interventions foster permanent peace or merely extend the duration of agreements that are ultimately doomed to fail. 
In doing so, cure models can provide greater theoretical leverage over peace agreements by facilitating a deeper understanding of the causal mechanisms that underlie the associations we observe. In addition, these findings may help inform policymakers by illuminating which features of a peace agreement are most important for ensuring long-term stability.

%One of the primary advantages of duration modeling techniques over alternatives such as ordinary least squares regression is their ability to deal with censored observations. By incorporating information on observations that have yet to fail into the estimation process, these models allow analysts to retain valuable information about the failure process and avoid the potential for bias introduced by the censoring process. However, in doing so, standard duration models assume that all censored observations eventually experience the event of interest. Although this assumption is sometimes justified (e.g., all political leaders will eventually lose office and all wars will eventually terminate), in many cases it is not. For example, it is difficult to justify the argument that all peace agreements will eventually fail and result in renewed conflict between the former belligerents.%TODO More examples here




\section{Software}
%Existing options
	% Parametric
		Several options exist for estimating parametric cure models in R and Stata. The \textbf{flexsurvcure} package \citep{amdahl2017} can be used to estimate parametric mixture and non-mixture cure models using a wide variety of parametric distributions. The \textbf{spduration} package \citep{beger2017a}, described in \citep{beger2017a}, can be used to estimate 1parametric mixture models using the Weibull or log-logistic distributions, and can incorporate the use of time-varying covariates. Parametric mixture and non-mixture cure models can also be estimated in Stata using the user-written \textit{strsmix} and \textit{strsnmix} commands \citep{lambert2007}.
		
	% Semiparametric
		Several options exist for estimating semiparametric cure models in R. The \textbf{smcure} package \citep{cai2012a}, described in \citep{cai2012}, allows for the estimation of semiparametric cure models. The \textbf{rcure} package \citep{han2017} builds on \textbf{smcure} to incorporate the use of a weakly informative prior on the incidence portion of the model to reduce the potential for separation and produce more stable bootstrap estimates. The \textbf{intercure} package \citep{brettas2016} will estimate the semiparametric non-mixture cure models and semiparametric mixture frailty cure models for interval censored data. 
		% The \textbf{nltm} package will estimate semiparametric non-mixture cure models. 
		% nltm was removed from CRAN for not keeping the package well-maintained, archived versions are available
		% semicure is defunct and was superseded by R
		% miCoPTCM
		% Gorcure
		% NPHMC
		% CR
		% geecure
		% thregI

I introduce a new R package, \textbf{tvcure}, designed to estimate the semiparametric PH mixture cure model with time-varying covariates. The primary contribution of the \textbf{tvcure} package is the ability to estimate the semiparametric PH mixture cure model using time-varying covariates, which is not currently supported by any other software package. In addition, the \textbf{tvcure} package provides a number of additional features designed to enhance the usability of these models.
	%Modeling choices
	% Latency - PH or AFT
	% Link Functions
	For the incidence component, the package supports the use of the logit, probit, and complementary log-log link functions. % alternatives not supported currently cauchit, log
	% Future: Can incorporate the use of Offsets
	In addition, the tvcure function can incorporate the use of stratification to allow for the estimation of separate conditional baseline hazard functions for different groups. 

Estimation is performed using the EM algorithm described above. The standard errors of $\bvec$ and $\gvec$ are estimated using the nonparametric bootstrap with stratified random sampling. 
%The \textbf{tvcure} package follows prior packages in using the nonparametric bootstrap using stratified random sampling to estimate the standard errors for both $\bvec$ and $\gvec$. 
Since this procedure requires rerunning the EM algorithm multiple times, the bootstrapping method can require a significant amount of time to complete. To ameliorate this issue, the \textbf{tvcure} package supports the use of parallel processing, allowing R to estimate multiple bootstrap replications simultaneously on separate processor cores. 

In addition, the \textbf{tvcure} package includes several functions designed to facilitate the interpretation and presentation of results. The package includes a prediction function for computing and plotting various quantities of interest for different covariate profiles, including the probability of failure, probability of cure, conditional survivor function, conditional baseline survivor function, and the marginal survivor population. At present, these functions are not capable of estimating confidence intervals for these quantities. However, the functionality to do so using simulation-based methods, as employed by \citet{beger2017}, is currently in development. In addition, a function designed to help produce publication ready tables in conjunction with the \textbf{xtable} package is included. These functions were used to create all results tables and predicted probabilities presented in the replication analysis.

%\section{Monte Carlo Simulations}

\section{Replication Analysis: International Ceasefires}

% Cox model 
For the sake of comparison, Table \ref{tab.lhr.cox} presents the results of a standard Cox proportional hazards model of cease-fire duration. Four variables appear to have significant effects on the hazard rate. Democracy has a negative effect on the hazard rate, and thus is associated with a longer peace spell after the end of a conflict. By contrast, battle deaths, existential stakes, and contiguity all have positive effects on the hazard rate.

\begin{table}
	\caption{Cox proportional hazards estimates for incidence and hazard of intrastate cease-fires} 
	\label{tab.lhr.cox}
	\include{coxtab}
	Note: *** p \textless 0.001, ** p \textless 0.01, * p \textless 0.05, . p \textless 0.10
\end{table}

% Introduction to Table 1
Table \ref{tab.lhr.cure} presents the results of a semiparametric cure model. For the sake of this replication, all variables are included in both equations to limit the extent to which inferences are dependent on model specification. (The variable for foreign imposed regime change is omitted from the hazard component of the model due to the fact that it perfectly predicts failure in the hazard equation (i.e., quasi-complete separation). This provides strong evidence that foreign-imposed regime change is associated with lower hazard rates.) It should be noted, however, that researchers can choose to selectively include different independent variables in each model if they choose to do so. 

\begin{table}
	\caption{Semiparametric cure model estimates for incidence and hazard of duration of intrastate cease-fires} 
	\label{tab.lhr.cure}
	\include{lhrtab}
	Note: *** p \textless 0.001, ** p \textless 0.01, * p \textless 0.05, . p \textless 0.10
\end{table}

% Incidence interpretation
Columns 1 and 2 present the coefficient estimates for the incidence equation and their standard errors. Positive coefficient estimates indicate that a covariate is associated with a higher probability of failure. Capability change has a positive and significant effect on the incidence, suggesting that dyads that experience a rapid change in relative power are much more likely to experience relative conflict. Wars that end in ties also have a higher probability of recurring. This suggests that wars that do not lead to a decisive victor are more likely to recur since they have not adequately resolved the information problem underlying conflict \citep{fearon1995}. Battle deaths also have a negative effect on the incidence of war recurrence which is significant at the 0.1 level. This suggests that more costly conflicts are better at conveying information to the disputing parties and are therefore less likely to recur, further supporting the information mechanism. Finally, conflict history has a significant positive effect on the incidence, indicating that states that have fought more in the past are less likely to remain at peace.

% Latency interpretation
Columns 3 and 4 of Table \ref{tab.lhr.cure} present the estimated hazard coefficients and their standard errors. Positive hazard coefficients indicate that a covariate is associated with a higher hazard rate, and hence, a lower survival time. Only one variable, capability change, has a significant effect on the hazard rate. Intriguingly, capability changes are associated with lower hazard rates, which is the opposite of the expectation established in the previous literature. Notably, several of the variables found to have an effect on the duration of peace previously do not have a significant effect in the cure model (contiguity, existential stakes, or democracy). Likewise, most of the variables found to have a significant effect in the cure model did not have an effect in the standard Cox model.

To further illustrate how cure models can improve substantive inferences, I examine the results for the capability change variable more closely. 
% Capability Change Substantive effects
Power shifts are central to rationalist explanations of conflict. As states gain power relative to their allies, their ability to elicit a favorable outcome in war increases. This incentivizes them to renegotiate the terms of an agreement. This, in turn, makes it difficult for them to credibly commit to future agreements \citep{fearon1995, powell2006}. Although existing studies have found evidence that power shifts decrease the duration of cease-fires \citep{werner1999, werner2005}, other studies have failed to replicate this finding \citep{fortna2003, lo2008}.

The results from the cure model tell a different story, and may explain, in part, why previous studies have produced conflicting results. On the one hand, shifts in capabilities are associated with a higher probability of failure. To illustrate this effect, Figure \ref{fig:lhr.cap.pp} plots the predicted probability of failure from 0 to 5.%\footnote{Although the observed range of this variable goes up to 4.46, values above 1 are extremely rare, and the effects become indistinguishable above 1. Focusing on the range from 0 to 1 allows the visualization of the effects within this range more clearly.} 
As illustrated, the predicted probability of failure approaches 1 as capabability changes approach 1, indicating a 100 percent relative difference in the two states capabilities over the previous year.
%abs(((cap_1-lagcap_1)/lagcap_1) - ((cap_2-lagcap_2)/lagcap_2))

\begin{figure}[htbp]\centering
	\caption{Predicted Probability of Failure at Different Levels of Capability Change}
	\includegraphics[width = 3in]{cappred}
	\label{fig:lhr.cap.pp}
\end{figure}

However, capability change also has a significant negative effect on the hazard and may actually extend the duration of peace among those states that are destined to fail. Figure \ref{fig:lhr.cap.surv} plots the conditional survival curve, i.e. the probability of surviving at least until time $t$ for individuals who are susceptible to failure, across different levels of capability change. Higher levels of capability change shift the survival curve upwards by a substantial margin, as high as 80 percent after roughly 21,500 days (60 years). 

\begin{figure}[htbp]\centering
	\caption{Conditional Survivor Function at Different Levels of Capability Change}
	\includegraphics[width = 3in]{capsurv}
	\label{fig:lhr.cap.surv}
\end{figure}

This finding suggests that states are unlikely to experience conflict when power shifts are small. However, if they do, those conflicts will occur quickly, which may suggest that other exogenous shocks that lead to uncertainty about capabilities or resolve are at play. By contrast, large power shocks make conflict recurrence likely, but also tend to extent the duration of peace before such conflicts occur. This finding is admittedly puzzling, but may lie in the fact that power shifts are unlikely to produce conflict instantaneously. Rather, the effect of power shifts depends on the rising power's expectations about the future \citep{bas2017}. If states expect that a power shift is temporary, they have incentives to capitalize on it immediately and fight while they have the upper hand. However, if states expect to continue gaining military power relative to their enemy, they actually have incentives to wait. As their power grows, their ability to win a conflict increases and their expected benefits from renegotiating an agreement increases. Moreover, if one state experiences an extended period of relative growth, the other's uncertainty about the other state's power will be diminished and may be more likely to accept a negotiated settlement.
% Timing

% latex table generated in R 3.4.1 by xtable 1.8-2 package
% Fri Apr 20 12:45:16 2018
\begin{comment}
\begin{table}[ht]
	\centering
	\begin{tabular}{rlrrrr}
		\hline
		& Parameter & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
		\hline
		1 & Dur\_(Intercept) & 4.00 & 0.24 & 16.84 & 0.00 \\ 
		2 & Dur\_polity2 & 0.21 & 0.03 & 6.78 & 0.00 \\ 
		3 & log(alpha) & -0.03 & 0.12 & -0.27 & 0.79 \\ 
		4 & Risk\_(Intercept) & 6.53 & 3.26 & 2.01 & 0.04 \\ 
		5 & Risk\_polity2 & 0.90 & 0.41 & 2.20 & 0.03 \\ 
		\hline
	\end{tabular}
\end{table}
\end{comment}

\section{Conclusion}
In this article, I introduce readers to the semi-parametric cure model.%  based on the counting process formulation of the Cox proportional hazards model. By exploiting a convenient equivalence between the Cox model and Poisson regression, I demonstrate that the zero-inflated Poisson model can be used to estimate a semi-parametric proportional hazards model.
%Semiparametric cure models allow users to estimate without making rigorous parametric assumptions about the shape of the underlying baseline hazard rate. 
	%In addition, this model can be easily estimated in popular software programs using preexisting packages and commands. Moreover, this model can easily accommodate more complex data structures such as time-varying covariates and repeated events.
Cure models allow users to model failure time in a more accurate way in the presence of immune or cured subjects by jointly modeling whether an event occurs and the timing of such events. In doing so, cure models have the potential reduce bias and provide greater substantive leverage over questions of theoretical interest.
%I use simulation studies to compare the performance of the ZIP estimator against a standard Cox model and an alternative parametric cure model. Relative to the Cox model, I find that the ZIP model provides more accurate estimates of the hazard coefficients. In addition, I assess the performance of each of these models with various proportions of observations that are cured. As the proportion of cured observations increases, the Cox model performs even worse than in the initial simulations. In addition, at higher levels of cured observations I find that the ZIP model outperforms a mixture Weibull model, even when the initial duration times were drawn from a Weibull distribution. This suggests that the use of the ZIP model may be warranted even in cases where analysts are comfortable making parametric assumptions about the shape of the baseline hazard. Moreover, this suggests that using a semi-parametric cure model is of even greater importance when we cannot confidently make assumptions about the shape of the baseline hazard. 

I also introduce new software in the form of the \textbf{tvcure} R package, designed to implement the semiparametric cure model with time varying covariates. Finally, I apply the model to data on international cease-fires demonstrates the potential inferential advantages of semiparametric cure models model over the standard Cox model. In future iterations of this paper, I plan to conduct additional replication analyses on studies in American politics and comparative politics to demonstrate the potential for semiparametric cure models to be applied widely within political science.

\newpage
\section{References}
\printbibliography[heading = none]



\end{document}


\begin{comment} % Measurement
# Structural factors that enable self-enforcing agreements
# Factors that result in changes to self-enforcing agreements

\begin{itemize}
\begin{singlespace}
\item \underline{Foreign Imposed Regime Change (FIRC)} is a dummy variable coded 1 if the conflict ended with the victor instituting regime change in the losing state.%\footnote{Data for this particular model come from \citet{werner1999}. LHR also test additional models using data from the ARCHIGOS dataset \citep{goemans2009}.}
\item \underline{Agreement Strength} is a 10 point additive index of the strength of a cease-fire agreement. See \citet{fortna2004b} for more information on the provisions included in this measure. %TODO Add the specific measures here.
\item \underline{Battle Deaths} measures the natural log of the combined number of casualties for both disputants in the previous conflict. Data come from \citet{clodfelter2002}. 
\item \underline{Battle Consistency} is a measure of how long the winner of the previous war had been dominating the conflict prior to victory. This measure ranges from 0 to 1, with 0 indicating the previous war ended in a stalemate and 1 indicating that the victor of the previous war held the upper hand for the entirety of the previous conflict. 
\item \underline{Third Party Intervention} is a dummy coded 1 if the cease-fire came about only as a result of significant third party pressure.
\item \underline{Tie} is a dummy variable coded 1 if the previous conflict results in a draw. Data for this variable come from the Correlates of War project.
\item \underline{Existential Stakes} is a dummy variable coded 1 if the existence of one of the disputants was threatened by the previous conflict. This variable is based on the International Crisis Behavior (ICB) dataset, Version 7.0, [CITATION] and supplemented by additional coding by LHR. %TODO Citation
\item \underline{Capability Change} is a summed measure of the change in capabilities in both disputants over their capabilities in the previous year.
\item \underline{Conflict History} accounts for the history of conflict between the two disputants by taking the ratio of the number of MIDs previously fought by the two disputants to the age of the dyad.
\item \underline{One Democracy} is a dummy variable coded one if at least one state has a Polity score of 6 or higher.
\item \underline{Two Democracies} is a dummy variable coded one if both states have a Polity score of 6 or higher.
\item \underline{Contiguity} is a dummy variable coded one if the disputants are contiguous states, defined by the COW Direct Contiguity Data Set version 3.0 \citep{stinnett2002}.
\end{singlespace}
\end{itemize}
\end{comment}

%%%%%%For the Appendix
%Model results table
\begin{comment}
Table \ref{tab_sim_60_10_haz} presents the estimated hazard coefficients ($\beta_i$) for each of the models run. 
\begin{table}
\caption{Average Estimates of Hazard Coefficients for Simulated Datasets}
\label{tab_sim_60_10_haz}
\input{"tab_sim_60_10_lat.tex"}
\end{table}

\begin{table}
\caption{Average Estimates of Latency Coefficients for Simulated Datasets}
\label{tab_sim_60_10_lat}
\input{tab_sim_60_10_lat}
\end{table}
\end{comment}

\end{document}
%%%%% Working through derivation of log-likelihood: based primarily on Sy and Talor

% Full likelihood function and components
L = PROD(A*B)PROD(C*D)
L1 = PROD(A*B)
L2 = PROD(C*D)

% Derive full log-likelihood
% Log of the product is the sum of the logs
ll = log[PROD(A*B)] + log[PROD(C*D)]
ll = {SUM[log(A)] + SUM(log(B))} + {SUM(log(C)) + SUM(log(D))}
ll = SUM[log(A)] + SUM(log(B)) + SUM(log(C)) + SUM(log(D))

% Define A, B, C, D and take the logs
A = p^y
log(A) = y * log(p)

B = (1-p)^{1-y}
log(B) = (1-y)log(1-p)

C = {hazard}^dy
log(C) = (dy)log(hazard)

D = exp(-yHexp(ZB))
log(D) = -yH
% S(t) = exp(-H(t))
log(D) = -y(-log[S(t)])
log(D) = y(log(S(t)))

% Plug in A, B, C, and D
ll = SUM[y * log(p)] + SUM[(1-y)log(1-p)] + SUM[(dy)log(hazard)] + SUM(ylog(S))

% Combine the first two sums and last two sums to create l1 and l2
l1 = SUM[y * log(p) + (1-y)log(1-p)]
l2 = SUM{(dy)log(hazard) + ylog[S(t)]} % The y in dy dissapears in Peng and Dear - I think this has to do with the switch to wi

Derived in this way, l1 is contingent on gamma and y
l2 is contingent on beta, H0 or S0 and y

%%%%% Expectation step
E(y | observed, params) =  wi = delta + (1-delta) [pSu / 1-p + p*S]

E(lc1) = SUM[w * log(pi) + (1-w)log(1-pi)]
E(lc2) = SUM[d * w * log(hazard) + w * log(S(t))] % how does w end up inside - different articles differ on this

%%%%% Maximization step
% The M-step in the EM algorithm is to maximize (5) and (6) with respect to the unknown parameters.

	% LM
	
	% Coxph

	% Survivor function
	\sohat = \exp\bigg(
	-\sum_{}^{}\frac{d}{\sum_{den}^{max}w(i)^{m}\exp(bx)}
	)
	
	s0t converge